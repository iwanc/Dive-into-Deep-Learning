## 1 过拟合、欠拟合及其解决方案

- 训练误差（training error）：模型在训练数据集上表现出的误差
- 泛化误差（generalization error）：模型在任意一个测试数据样本上表现出的误差的期望，并常常通过测试数据集上的误差来近似（机器学习模型应关注降低泛化误差）
- 计算训练误差和泛化误差：线性回归用到的平方损失函数和softmax回归用到的交叉熵损失函数
- 欠拟合现象（underfitting）：模型无法达到一个较低的训练误差
- 过拟合现象（overfitting）：模型的训练误差远小于它在测试数据集上的误差

## 2 梯度消失、梯度爆炸

- 梯度消失和梯度爆炸：深度模型有关数值稳定性的典型问题是消失（vanishing）和爆炸（explosion）。当神经网络的层数较多时，模型的数值稳定性容易变差。当层数较多时，梯度的计算也容易出现消失或爆炸
- 模型训练实战步骤：获取数据集-数据预处理-模型设计-模型验证和模型调整（调参）-模型预测以及提交

## 3 循环神经网络进阶

- 循环神经网络（Recurrent Neural Network, RNN）是一类常用在序列数据上的人工神经网络。三种最常见的循环神经网络分别是：
  - RNN（vanilla RNN 维尼拉循环神经网络）
  - LSTM（Long-Short Term Memory 长短期记忆网络）：1997年提出
  - GRU（Gate Recurrent Unit 门控循环单元网络）：2014年提出，[人人都能看懂的GRU](https://zhuanlan.zhihu.com/p/32481747)